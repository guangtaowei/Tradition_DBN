{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.regression import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# import GridSearchCV\n",
    "\n",
    "import xlrd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "path_DBN = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"deep-belief-network\")\n",
    "sys.path.append(path_DBN)\n",
    "from dbn.tensorflow import SupervisedDBNRegression\n",
    "\n",
    "# path_CRBM = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"CRBM-DBN\")\n",
    "# sys.path.append(path_CRBM)\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# path_data = \"data/data.xls\"\n",
    "path_data = \"data/airdata.xlsx\"\n",
    "path_out_txt = \"out/out.txt\"\n",
    "path_out_png = \"out/out.png\"\n",
    "\n",
    "data = xlrd.open_workbook(path_data)\n",
    "table = data.sheet_by_index(0)\n",
    "data_num = table.nrows - 1\n",
    "pm25 = table.col_values(2)[1:]\n",
    "pm25 = np.array(pm25)\n",
    "temperature = table.col_values(8)[1:]\n",
    "temperature = np.array(temperature)\n",
    "wind = table.col_values(9)[1:]\n",
    "wind = np.array(wind)\n",
    "weather = table.col_values(10)[1:]\n",
    "weather = np.array(weather)\n",
    "moisture = table.col_values(11)[1:]\n",
    "moisture = np.array(moisture)\n",
    "\n",
    "use_min_max_scaler = True\n",
    "use_all_data = False\n",
    "use_CCA_data = True\n",
    "use_deep = False\n",
    "step = 1\n",
    "train_deep = 50\n",
    "train_start = 51\n",
    "predict_start = 52\n",
    "\n",
    "assert step > 0\n",
    "assert train_deep >= step and train_start >= train_deep\n",
    "assert predict_start > train_start\n",
    "assert not (True == use_all_data and True == use_CCA_data)\n",
    "\n",
    "regressor_DBN = SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                        learning_rate_rbm=0.01,\n",
    "                                        learning_rate=0.01,\n",
    "                                        n_epochs_rbm=20,\n",
    "                                        n_iter_backprop=200,\n",
    "                                        batch_size=32,\n",
    "                                        activation_function='sigmoid',\n",
    "                                        verbose=False)\n",
    "regressor_AdaBoost = AdaBoostRegressor()\n",
    "regressor_DBNAdaBoost = AdaBoostRegressor(SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                                               learning_rate_rbm=0.01,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               n_epochs_rbm=20,\n",
    "                                                               n_iter_backprop=200,\n",
    "                                                               batch_size=16,\n",
    "                                                               activation_function='sigmoid',\n",
    "                                                               verbose=False),\n",
    "                                       loss=\"square\",\n",
    "                                       n_estimators=250,\n",
    "                                       learning_rate=50)\n",
    "regressor_SVM = svm.SVR()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "open(path_out_txt, 'w').close()\n",
    "\n",
    "if use_all_data:\n",
    "    Data = np.concatenate((pm25[0:step], temperature[0:step], wind[0:step], weather[0:step], moisture[0:step]), axis=0)\n",
    "else:\n",
    "    if use_CCA_data:\n",
    "        Data = np.concatenate((pm25[0:step], temperature[0:step], moisture[0:step]), axis=0)\n",
    "    else:\n",
    "        Data = pm25[0:step]\n",
    "\n",
    "Target = pm25[step]\n",
    "\n",
    "correct = []\n",
    "predict_DBN = []\n",
    "predict_DBNAdaBoost = []\n",
    "predict_AdaBoost = []\n",
    "predict_SVM = []\n",
    "loss_total_DBN = 0.0\n",
    "loss_total_DBNAdaBoost = 0.0\n",
    "loss_total_AdaBoost = 0.0\n",
    "loss_total_SVM = 0.0\n",
    "\n",
    "logging.debug(\"data_num:%s\", data_num)\n",
    "\n",
    "for i in range(step + 1, data_num):\n",
    "\n",
    "    if use_all_data:\n",
    "        train_data_last = np.concatenate(\n",
    "            (pm25[i - step:i], temperature[i - step:i], wind[i - step:i], weather[i - step:i], moisture[i - step:i]),\n",
    "            axis=0)\n",
    "    else:\n",
    "        if use_CCA_data:\n",
    "            train_data_last = np.concatenate((pm25[i - step:i], temperature[i - step:i], moisture[i - step:i]), axis=0)\n",
    "        else:\n",
    "            train_data_last = pm25[i - step:i]\n",
    "    logging.debug(\"train_data_last:%s\", train_data_last.shape)\n",
    "    Data = np.row_stack((Data, train_data_last))\n",
    "    Target = np.row_stack((Target, pm25[i]))\n",
    "\n",
    "    # predicting\n",
    "    if i > predict_start:\n",
    "        if use_min_max_scaler:\n",
    "            train_data_last = train_data_last.reshape((1, train_data_last.size))\n",
    "            tmp_test = min_max_scaler.transform(train_data_last)\n",
    "        else:\n",
    "            train_data_last = train_data_last.reshape((1, train_data_last.size))\n",
    "            tmp_test = train_data_last\n",
    "\n",
    "        logging.debug(\"train_data_last:%s\", train_data_last)\n",
    "        logging.debug(\"tmp_test:%s\", tmp_test)\n",
    "        tmp_pred_DBN = regressor_DBN.predict(tmp_test)[0][0]\n",
    "        tmp_pred_DBNAdaBoost = regressor_DBNAdaBoost.predict(tmp_test)[0][0][0][0]\n",
    "        tmp_pred_AdaBoost = regressor_AdaBoost.predict(tmp_test)[0]\n",
    "        tmp_pred_SVM = regressor_SVM.predict(tmp_test)[0]\n",
    "        logging.info(\"==========================================\")\n",
    "        logging.info(\"pred_DBN:%s\", tmp_pred_DBN)\n",
    "        logging.info(\"pred_DBNAdaBoost:%s\", tmp_pred_DBNAdaBoost)\n",
    "        logging.info(\"pred_AdaBoost:%s\", tmp_pred_AdaBoost)\n",
    "        logging.info(\"pred_SVM:%s\", tmp_pred_SVM)\n",
    "        logging.info(\"correct:%s\", pm25[i])\n",
    "        logging.info(\"==========================================\")\n",
    "\n",
    "        predict_DBN.append(tmp_pred_DBN)\n",
    "        predict_DBNAdaBoost.append(tmp_pred_DBNAdaBoost)\n",
    "        predict_AdaBoost.append(tmp_pred_AdaBoost)\n",
    "        predict_SVM.append(tmp_pred_SVM)\n",
    "        correct.append(pm25[i])\n",
    "\n",
    "        with open(path_out_txt, 'a') as f:\n",
    "            loss_DBN = math.sqrt(math.pow(tmp_pred_DBN - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_DBN += loss_DBN\n",
    "            loss_DBNAdaBoost = math.sqrt(math.pow(tmp_pred_DBNAdaBoost - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_DBNAdaBoost += loss_DBNAdaBoost\n",
    "            loss_AdaBoost = math.sqrt(math.pow(tmp_pred_AdaBoost - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_AdaBoost += loss_AdaBoost\n",
    "            loss_SVM = math.sqrt(math.pow(tmp_pred_SVM - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_SVM += loss_SVM\n",
    "            f.write(\n",
    "                \"p_D:%f\\tp_DA:%f\\tp_A:%f\\tp_S:%f\\tc:%f\\t\\tl_D:%f\\tl_DA:%f\\tl_A:%f\\tl_S:%f\\t\\tR2_D:%f\\tR2_DA:%f\\tR2_A:%f\\tR2_S:%f\\t\\tl_avg_D:%f\\tl_avg_DA:%f\\tl_avg_A:%f\\tl_avg_S:%f\\n\" % (\n",
    "                    tmp_pred_DBN, tmp_pred_DBNAdaBoost,tmp_pred_AdaBoost, tmp_pred_SVM, pm25[i], loss_DBN,loss_DBNAdaBoost, loss_AdaBoost, loss_SVM,\n",
    "                    r2_score(correct, predict_DBN), r2_score(correct, predict_DBNAdaBoost),r2_score(correct, predict_AdaBoost),\n",
    "                    r2_score(correct, predict_SVM), loss_total_DBN / (i - predict_start),\n",
    "                    loss_total_DBNAdaBoost / (i - predict_start),\n",
    "                    loss_total_AdaBoost / (i - predict_start),\n",
    "                    loss_total_SVM / (i - predict_start)))\n",
    "\n",
    "        x_range = range(i - predict_start)\n",
    "        plt.clf()\n",
    "        plt.plot(x_range, predict_DBN, marker='o', label=\"DBN\")\n",
    "        plt.plot(x_range, predict_DBNAdaBoost, marker='o', label=\"DBNAdaBoost\")\n",
    "        plt.plot(x_range, predict_AdaBoost, marker='o', label=\"AdaBoost\")\n",
    "        plt.plot(x_range, predict_SVM, marker='o', label=\"SVM\")\n",
    "        plt.plot(x_range, correct, marker='o', label=\"correct\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.savefig(path_out_png)\n",
    "\n",
    "    # training\n",
    "    if i > train_start:\n",
    "        if use_min_max_scaler:\n",
    "            if use_deep:\n",
    "                tmp_data = min_max_scaler.fit_transform(Data[i - train_deep:i])\n",
    "            else:\n",
    "                tmp_data = min_max_scaler.fit_transform(Data)\n",
    "        else:\n",
    "            if use_deep:\n",
    "                tmp_data = Data[i - train_deep:i]\n",
    "            else:\n",
    "                tmp_data = Data\n",
    "        logging.debug(\"Data:%s\", Data.shape)\n",
    "        logging.debug(\"tmp_data:%s\", tmp_data.shape)\n",
    "        if use_deep:\n",
    "            regressor_DBN.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "            regressor_DBNAdaBoost.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "            regressor_AdaBoost.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "            regressor_SVM.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "        else:\n",
    "            regressor_DBN.fit(tmp_data, Target[:, 0])\n",
    "            regressor_DBNAdaBoost.fit(tmp_data, Target[:, 0])\n",
    "            regressor_AdaBoost.fit(tmp_data, Target[:, 0])\n",
    "            regressor_SVM.fit(tmp_data, Target[:, 0])\n",
    "\n",
    "logging.info(\n",
    "    'Done.\\nDBN:\\tR-squared: %f\\nMSE: %f' % (r2_score(correct, predict_DBN), mean_squared_error(correct, predict_DBN)))\n",
    "logging.info('DBNAdaBoost:\\tR-squared: %f\\nMSE: %f' % (\n",
    "    r2_score(correct, predict_DBNAdaBoost), mean_squared_error(correct, predict_DBNAdaBoost)))\n",
    "logging.info('AdaBoost:\\tR-squared: %f\\nMSE: %f' % (\n",
    "    r2_score(correct, predict_AdaBoost), mean_squared_error(correct, predict_AdaBoost)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
